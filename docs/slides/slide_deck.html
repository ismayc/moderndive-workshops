<!DOCTYPE html>
<html>
  <head>
    <title>A Fully Customizable Textbook for Introductory Statistics/Data Science</title>
    <meta charset="utf-8">
    <meta name="author" content="Chester Ismay and Albert Y. Kim" />
    <link rel="stylesheet" href="example.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# A Fully Customizable Textbook for Introductory Statistics/Data Science
## USCOTS 2017 Workshop
### Chester Ismay and Albert Y. Kim
### May 17 &amp; 18, 2017 <br><br> Slides at <a href="http://bit.ly/uscots17-slides" class="uri">http://bit.ly/uscots17-slides</a> <br> Supplementary HTML document at <a href="http://bit.ly/uscots17-html" class="uri">http://bit.ly/uscots17-html</a>

---


&lt;!-- Write slide link on whiteboard --&gt;



&lt;!-----------------------------------------------------------------------------&gt;
# Introduction

## Who We Are

* [Chester Ismay](https://ismayc.github.io/): Reed College &amp; Pacific University
    + Email: &lt;chester.ismay@gmail.com&gt;
    + GitHub: [`ismayc`](https://github.com/ismayc)
    + Twitter: [`@old_man_chester`](https://twitter.com/old_man_chester)
* [Albert Y. Kim](http://rudeboybert.github.io/): Middlebury College
    + Email: &lt;albert.ys.kim@gmail.com&gt;
    + GitHub: [`rudeboybert`](https://github.com/rudeboybert)
    + Twitter: [`@rudeboybert`](https://twitter.com/rudeboybert)

---

class: center, middle

## Outline of Workshop

[Google Doc at &lt;http://bit.ly/uscots17-agenda&gt;](https://docs.google.com/document/d/12Ai7wxK5OTrIwwrSJQewXHcqpMJ09lB-HkGN3BbShy4/edit?usp=sharing)


---

## Our Textbook

&lt;img src="figure/moderndive-logo.png" height="75px"/&gt;

* *An Introduction to Statistical and Data Sciences via R*
* Webpage: &lt;http://moderndive.com&gt;. [GitHub Repo](https://github.com/ismayc/moderndiver-book)
* In you haven't already, please [signup](http://moderndive.us15.list-manage2.com/subscribe?u=87888fab720da90906427a5be&amp;id=0c9e2d1df2) for our mailing list!



---

## Albert's Course (Intro to Statistical &amp; Data Sciences)

Available in the supplementary HTML document [here].

* [Webpage](https://rudeboybert.github.io/MATH116/) and [GitHub Repo](https://github.com/rudeboybert/MATH116)
* Administrative:
    + Chief non-econ/bio stats service class at Middlebury
    + 12 weeks each with 3h "lecture" + 1h "lab"
    + &lt;u&gt;No prerequisites&lt;/u&gt;
* Students:
    + ~24 students/section of all years/backgrounds. Only stats class many will take
    + Background: Many had AP stats, some with programming
    + All had laptops that they brought everyday
* [Topic List](https://rudeboybert.github.io/MATH116/)
    + &lt;u&gt;First half is data science&lt;/u&gt;: data visualization, manipulation, importing
    + &lt;u&gt;Second half is intro stats&lt;/u&gt;: sampling, hypothesis tests, CI, regression
* Evaluation
    + 10%: weekly problem sets
    + 10%: engagement
    + 45%: 3 midterms (last during finals week)
    + &lt;u&gt;35%: [Final projects](https://rudeboybert.github.io/MATH116/PS/final_project/final_project_outline.html#learning_goals)&lt;/u&gt;
* Typical Classtime:
    + First 10-15min: Priming topic, either via slides or &lt;u&gt;chalk talk&lt;/u&gt;
    + Remainder: Students read over text &amp; do &lt;u&gt;Learning Checks&lt;/u&gt; in groups and without direct instructor guidance. 


---

## Chester's Course (Social Statistics)

Available in the supplementary HTML document [here].

* [Webpage at &lt;http://bit.ly/soc-301&gt;](https://ismayc.github.io/soc301_s2017/)  and [GitHub Repo](https://github.com/ismayc/soc301_s2017)
* Administrative:
    + Chief stats service class for sociology/criminal justice
    + An option take to fulfill the Pacific U. math requirement
    + 14 weeks, meeting on Tues &amp; Thurs for 95 minutes
    + &lt;u&gt;No prerequisites&lt;/u&gt;
* Students:
    + 26 students of all years/backgrounds. Only stats class many will take
    + Background: 3 had AP stats, zero with programming
    + All had laptops that they brought everyday
* [Course Schedule](https://ismayc.github.io/soc301_s2017/schedule/)
    + &lt;u&gt;First half is data science&lt;/u&gt;: data visualization, wrangling, importing
    + &lt;u&gt;Second half is intro stats&lt;/u&gt;: sampling, testing, CI
* [Evaluation](https://ismayc.github.io/soc301_s2017/syllabus/)
    + 5%: Engagement/Pass-fail Learning Checks
    + 10%: DataCamp/article summarizing assignments
    + &lt;u&gt;15%: [Group Project](https://ismayc.github.io/soc301_s2017/group-projects/index.html)&lt;/u&gt;    
    + 20%: Pencil-and-paper Midterm Exam
    + 25%: (5) Multiple choice cumulative quizzes
    + 25%: Cumulative Pencil-and-paper Final Exam
* Typical Classtime:
    + First 5-10min: Students answer warmup exercise based on previous content
    + Next 10-20min: Review reading assignment via [slides](http://ismayc.github.io/soc301_s2017/slides/slide_deck.html)
    + Bulk of class: 
        - Students read over text &amp; do &lt;u&gt;Learning Checks&lt;/u&gt; in groups and without direct instructor guidance. 
        - Students work on next DataCamp problems and ask questions as needed
    + Last 5-10min:  Go over warmup exercise again or quiz students on material from that period   

---

## What Are We Doing And Why?

1. Data first! Start with data science via `tidyverse`, &lt;br&gt; then stats builds on these ideas.
1. Replacing the &lt;u&gt;mathematical/analytic&lt;/u&gt; with &lt;u&gt;computational/simulation-based&lt;/u&gt; whenever possible.
1. The above necessitates algorithmic thinking, computational logic and some coding/programming.
1. Complete reproducibility



---

## 1) Data First!

Cobb ([TAS 2015](https://arxiv.org/abs/1507.05346)): *Minimizing prerequisites to research*. In other words, focus on entirety of Wickham/Grolemund's pipeline...

![](figure/pipeline.png)



---

## 1) Data First!

Furthermore use data science tools &lt;u&gt;that a data scientist would use&lt;/u&gt;. Example: [`tidyverse`](http://tidyverse.org/)

&lt;br&gt;

&lt;center&gt;&lt;img src="figure/hex.png" height="300px"/&gt;&lt;/center&gt;

---

## 1) Data First!

What does this buy us?

* Students can do effective data storytelling
* Context for asking scientific questions
* Look at data that's rich, real, and realistic. Examples: Data packages such as [`nycflights13`](https://github.com/hadley/nycflights13) and [`fivethirtyeight`](https://cran.r-project.org/web/packages/fivethirtyeight/vignettes/fivethirtyeight.html)
* Better motivate traditional statistical topics

---

## 2) Computers, Not Math!

Cobb ([TAS 2015](https://arxiv.org/abs/1507.05346)): Two possible "computational
engines" for statistics, in particular relating to sampling:

* Mathematics: formulas, probability theory, large-sample approximations, central limit theorem

--

* Computers: simulations, resampling methods

---

## 2) Computers, Not Math!

We present students with a choice for our "engine":

&lt;br/&gt;

Either we use this...            |  Or we use this...
:-------------------------:|:-------------------------:
&lt;img src="figure/formulas.png" alt="Drawing" style="width: 250px;"/&gt;   |  &lt;img src="figure/coding.jpg" alt="Drawing" style="width: 250px;"/&gt; 

&lt;br/&gt;

--

* Almost all are thrilled to do the latter

--

* Leave "bread crumbs" for more advanced math/stats courses

---

## 2) Computers, Not Math!

What does this buy us?

* Emphasizes: stats is not math, rather stats uses math.
* Simulations are more tactile
* Reducing probability and march to CLT, this frees up space in syllabus.

---

## 3) Algorithms, Computation, &amp; Coding

* Both "Data First!" and "Computers, Not Math!" necessitate algorithmic thinking, computational logic, and some coding/programming.
* Battle is more psychological than anything:
    + "This is not a class on programming!"
    + "Computers are stupid!"
    + "Learning to code is like learning a foreign language!"
    + "Early on don't code from scratch! Take something else that's similar and tweak it!"
    + Learning how to Google effectively

---

## 3) Algorithms, Computation, &amp; Coding

Why should we do this?

* Data science and machine learning.
* Where statistics is heading. Gelman [blog post](http://andrewgelman.com/2017/05/14/computer-programming-prerequisite-learning-statistics/).
* We are doing a disservice to students by shielding them from these computational ideas.
* Bigger picture: Coding is becoming a basic skill like reading and writing.



---

## 4) Complete Reproducibility

* Students learn best when they can take apart a toy (analysis) and then rebuild it (synthesis).
* Crisis in Reproducibility
* Ultimately the best textbook is one you've written yourself.
    + Everyone has different contexts, backgrounds, needs
    + Hard to find one-size-fits-all solutions
* A new paradigm in textbooks? [Versions, not editions?](https://twitter.com/rudeboybert/status/820032345759592448)

---

class: center, middle, inverse

## Let's Dive In!

&lt;a href="https://giphy.com/gifs/season-6-the-simpsons-6x1-l2Je1bFuOpkNpyqYM/"&gt;&lt;img src="figure/homer.gif" style="width: 600px;"/&gt;&lt;/a&gt;

---

&lt;!-----------------------------------------------------------------------------&gt;
# Getting Started

## DataCamp

DataCamp offers an interactive, browser based tool for learning R/Python. Their
two flagship R courses, both of which are free:

* [Intro to R](https://www.datacamp.com/courses/free-introduction-to-r) 
* [Intermediate R](https://www.datacamp.com/courses/intermediate-r-practice) courses

---

## DataCamp

Outsource many essential but not fun to teach topics like

* Idea of command-line vs point-and-click
* Syntax: Variable names typed exactly, parentheses matching
* Algorithmic Thinking: Linearity of code, object assignment
* Computational Logic: boolean algebra, conditional statements, functions

---

## DataCamp Pros

* Can assign "Intro to R" first day of class as "Homework 0"
* Outsourcing allows you to free up class time
* Students get immediate feedback on whether or not their code works
    + Often, the DataCamp error messages are much more useful than the ones R gives

---

## DataCamp Pros
    
* With their [free academic license](https://www.datacamp.com/groups/education), you can
    + Form class "Groups" and assign/track progress of DataCamp courses
    + Have free access to ALL [their courses](https://www.datacamp.com/courses), including `ggplot2`, `dplyr`, `rmarkdown`, and RStudio IDE.
    + Create your own free DataCamp course covering content you want your students to learn using R

---

## DataCamp Cons

* Some students will still have trouble; you can identify them however.
* The topics in these two free courses may not align with your syllabus. You can assign at chapter level instead of course level though

---

## DataCamp Conclusion

* Not a good tool for "quick retention", but for R concept introduction and subsequent repetition.
  + Students need to practice "speaking the language" just like with a foreign language.
* [Feedback](https://docs.google.com/spreadsheets/d/1qUwt-v-xAQJ-1OTzMI2Q27McXG_3yXO5Qe9p-jz6BA8/edit) from students was positive.
* Battle is more psychological than anything. DataCamp reinforces to students that
    + "Computers are stupid!"
    + "Learning to code is like learning a foreign language!"

---

## Chester's First Bookdown Project

[Getting used to R, RStudio, and R Markdown](https://ismayc.github.io/rbasics-book/)

- Designed to provide students with GIFs to follow along with and a description of all the components of RStudio and R Markdown

---

class: inverse, center, middle

## Short break?

---

## Important R ideas for students to know ASAP

Vector/variable
  - Type of vector (`int`, `num`, `chr`, `logical`, `date`)

--

Data frame
  - Vectors of (potentially) different types
  - Each vector has the same number of rows
  
---

class: center, middle  
  
# Welcome to the [tidyverse](https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/)!
  
The `tidyverse` is a collection of R packages that share common philosophies and are designed to work together. &lt;br&gt;&lt;br&gt; 
  
&lt;a href="http://tidyverse.tidyverse.org/logo.png"&gt;&lt;img src="figure/tidyverse.png" style="width: 200px;"/&gt;&lt;/a&gt;

---

# Chapter 3: Tidy Data?

&lt;img src="http://garrettgman.github.io/images/tidy-1.png" alt="Drawing" style="width: 750px;"/&gt;

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

The third point means we don't mix apples and oranges.

---

## What is Tidy Data?

1. Each observation forms a row. In other words, each row corresponds to a single instance of an &lt;u&gt;observational unit&lt;/u&gt;
1. Each variable forms a column:
    + Some variables may be used to identify the &lt;u&gt;observational units&lt;/u&gt;. 
    + For organizational purposes, it's generally better to put these in the left-hand columns
1. Each type of observational unit forms a table.

---

## Differentiating between &lt;u&gt;neat&lt;/u&gt; data and &lt;u&gt;tidy&lt;/u&gt; data

- Colloquially, they mean the same thing
- But in our context, one is a subset of the other. 

&lt;br&gt;

&lt;u&gt;Neat&lt;/u&gt; data is 
  - easy to look at, 
  - organized nicely, and 
  - in table form.

--

&lt;u&gt;Tidy&lt;/u&gt; data is neat but also abides by a set of three rules.

---

class: center, middle

&lt;a href="figure/lebowski-abides-o.gif"&gt;&lt;img src="http://stream1.gifsoup.com/view8/20150404/5192859/lebowski-abides-o.gif" style="width: 450px;"/&gt;&lt;/a&gt;


&lt;img src="figure/tidy-1.png" alt="Drawing" style="width: 750px;"/&gt;

---

## Is this tidy?


```
# A tibble: 12 × 4
    year                        title clean_test budget_2013
   &lt;int&gt;                        &lt;chr&gt;      &lt;chr&gt;       &lt;int&gt;
1   1995                    Apollo 13         ok    99370665
2   2005           Brokeback Mountain     notalk    16583160
3   2010         Diary of a Wimpy Kid         ok    16023478
4   1984                         Dune    dubious   100864980
5   1984                 Ghostbusters     notalk    67243320
6   2003 How to Lose a Guy in 10 Days        men    63304348
7   2011                         Iris         ok     5696299
8   2004                     Sideways         ok    20964279
9   2000                  Songcatcher         ok     2435235
10  2004   Team America: World Police        men    24663858
11  2010                  Tron Legacy     notalk   213646368
12  2011                    War Horse     notalk    72498355
```


---

name: demscore

## How about this? Is this tidy?


```
# A tibble: 12 × 13
      country `1952` `1957` `1962` `1967` `1972` `1977` `1982` `1987`
        &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;
1     Albania     -9     -9     -9     -9     -9     -9     -9     -9
2   Argentina     -9     -1     -1     -9     -9     -9     -8      8
3     Armenia     -9     -7     -7     -7     -7     -7     -7     -7
4   Australia     10     10     10     10     10     10     10     10
5     Austria     10     10     10     10     10     10     10     10
6  Azerbaijan     -9     -7     -7     -7     -7     -7     -7     -7
7     Belarus     -9     -7     -7     -7     -7     -7     -7     -7
8     Belgium     10     10     10     10     10     10     10     10
9      Bhutan    -10    -10    -10    -10    -10    -10    -10    -10
10    Bolivia     -4     -3     -3     -4     -7     -7      8      9
11     Brazil      5      5      5     -9     -9     -4     -3      7
12   Bulgaria     -7     -7     -7     -7     -7     -7     -7     -7
# ... with 4 more variables: `1992` &lt;int&gt;, `1997` &lt;int&gt;, `2002` &lt;int&gt;,
#   `2007` &lt;int&gt;
```

&lt;small&gt;&lt;small&gt;[Why is tidy data important?](#whytidy) slide&lt;/small&gt;&lt;/small&gt;

---

## Beginning steps

Frequently the first thing to do when given a dataset is to

- check that the data is &lt;u&gt;tidy&lt;/u&gt;,
- identify the observational unit,
- specify the variables, and
- give the types of variables you are presented with.

This will help with 

- choosing the appropriate plot, 
- summarizing the data, and 
- understanding which inferences can be applied.

---

class: center, middle

# Chapter 4: Data Viz

&lt;a href="http://gitsense.github.io/images/wealth.gif"&gt;&lt;img src="figure/wealth.gif" style="width: 770px;"/&gt;&lt;/a&gt;

Inspired by [Hans Rosling](https://www.youtube.com/watch?v=jbkSRLYSojo)

---

&lt;img src="slide_deck_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;


- What are the variables here?
- What is the observational unit?
- How are the variables mapped to aesthetics?

---

class: center, middle

## Grammar of Graphics

Wilkinson (2005) laid out the proposed "Grammar of Graphics"

&lt;a href="http://www.powells.com/book/the-grammar-of-graphics-9780387245447"&gt;&lt;img src="figure/graphics.jpg" style="width: 200px;"&gt;&lt;/a&gt;

---

class: center, middle

## Grammar of Graphics in R

Wickham implemented the grammar in R in the `ggplot2` package

&lt;a href="http://www.powells.com/book/ggplot2-elegant-graphics-for-data-analysis-9783319242750/68-428"&gt;&lt;img src="figure/ggplot2.jpg" style="width: 200px;"&gt;&lt;/a&gt;

---

class: center, middle

## What is a statistical graphic?

--

## A `mapping` of &lt;br&gt; `data` variables

--

## to &lt;br&gt; `aes()`thetic attributes

--

## of &lt;br&gt; `geom_`etric objects.

---

class: inverse, center, middle

## Back to basics

---

### Consider the following data in tidy format:


```
# A tibble: 4 × 4
      A     B     C     D
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
1  1980     1     3   low
2  1990     2     2   low
3  2000     3     1  high
4  2010     4     2  high
```

&lt;!-- Copy to chalkboard/whiteboard --&gt;

- Sketch the graphics below on paper, where the `x`-axis is variable `A` and the `y`-axis is variable `B`

1. &lt;small&gt;A scatter plot&lt;/small&gt;
1. &lt;small&gt;A scatter plot where the `color` of the points corresponds to `D`&lt;/small&gt;
1. &lt;small&gt;A scatter plot where the `size` of the points corresponds to `C`&lt;/small&gt;
1. &lt;small&gt;A line graph&lt;/small&gt;
1. &lt;small&gt;A line graph where the `color` of the line corresponds to `D` with points added that are all green of size 4.&lt;/small&gt;

---

## Reproducing the plots in &lt;small&gt;`ggplot2`&lt;/small&gt;

### 1. A scatterplot


```r
library(ggplot2)
ggplot(data = simple_ex, mapping = aes(x = A, y = B)) + 
  geom_point()
```
--

![](slide_deck_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;


---


## Reproducing the plots in &lt;small&gt;`ggplot2`&lt;/small&gt;

### 2. A scatter plot where the `color` of the points corresponds to `group`


```r
library(ggplot2)
ggplot(data = simple_ex, mapping = aes(x = A, y = B)) + 
  geom_point(mapping = aes(color = D))
```
--

![](slide_deck_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;


---

## Reproducing the plots in &lt;small&gt;`ggplot2`&lt;/small&gt;

### 3. A scatter plot where the `size` of the points corresponds to `C`


```r
library(ggplot2)
ggplot(data = simple_ex, mapping = aes(x = A, y = B, size = C)) + 
  geom_point()
```
--

![](slide_deck_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;


---

## Reproducing the plots in &lt;small&gt;`ggplot2`&lt;/small&gt;

### 4. A line graph


```r
library(ggplot2)
ggplot(data = simple_ex, mapping = aes(x = A, y = B)) + 
  geom_line()
```
--

![](slide_deck_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;


---

## Reproducing the plots in &lt;small&gt;`ggplot2`&lt;/small&gt;

### 5. A line graph where the `color` of the line corresponds to `D` with points added that are all blue of size 4.


```r
library(ggplot2)
ggplot(data = simple_ex, mapping = aes(x = A, y = B)) + 
  geom_line(mapping = aes(color = D)) +
  geom_point(color = "blue", size = 4)
```
--

![](slide_deck_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

---

name: whytidy

## Why is tidy data important?

- Think about trying to plot democracy score across years in the simplest way possible with the data on the [Is this tidy? slide](#demscore).
--

- It would be much easier if the data looked like what follows instead so we could put 
    - `year` on the `x`-axis and 
    - `dem_score` on the `y`-axis.

---

## Tidy is good


```
# A tibble: 13 × 3
       country  year dem_score
         &lt;chr&gt; &lt;dbl&gt;     &lt;int&gt;
1    Argentina  1962        -1
2      Armenia  1997        -6
3      Denmark  1962        10
4     Ethiopia  2007         1
5      Finland  2007        10
6      Ireland  1992        10
7        Libya  1957        -7
8        Libya  1982        -7
9       Mexico  1977        -3
10      Mexico  1982        -3
11       Spain  1962        -7
12 Switzerland  1982        10
13     Ukraine  1997         7
```

---

## Let's plot it

- Plot the line graph for 4 countries using `ggplot`


```r
dem_score4 &lt;- dem_score_tidy %&gt;%
  filter(country %in% c("Australia", "Pakistan", "Portugal", "Uruguay"))
ggplot(data = dem_score4, mapping = aes(x = year, y = dem_score)) +
  geom_line(mapping = aes(color = country))
```

![](slide_deck_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

# The Five-Named Graphs 

## The 5NG of data viz

- Scatterplot: `geom_point()`
- Line graph: `geom_line()`
--

- Histogram: `geom_histogram()`
- Boxplot: `geom_boxplot()`
- Bar graph: `geom_bar()`


---

class: center, middle

## More examples

---

## Histogram


```r
library(nycflights13)
ggplot(data = weather, mapping = aes(x = humid)) +
  geom_histogram(bins = 20, color = "black", fill = "darkorange")
```

![](slide_deck_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

---

## Boxplot (broken)


```r
library(nycflights13)
ggplot(data = weather, mapping = aes(x = month, y = humid)) +
  geom_boxplot()
```

![](slide_deck_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;

---


## Boxplot (fixed)


```r
library(nycflights13)
ggplot(data = weather, mapping = aes(x = factor(month), y = humid)) +
  geom_boxplot()
```

![](slide_deck_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

---

## Bar graph


```r
library(fivethirtyeight)
ggplot(data = bechdel, mapping = aes(x = clean_test)) +
  geom_bar()
```

![](slide_deck_files/figure-html/unnamed-chunk-21-1.png)&lt;!-- --&gt;

---

## How about over time?

- Hop into `dplyr`


```r
library(dplyr)
year_bins &lt;- c("'70-'74", "'75-'79", "'80-'84", "'85-'89",
               "'90-'94", "'95-'99", "'00-'04", "'05-'09",
               "'10-'13")
bechdel &lt;- bechdel %&gt;%
  mutate(five_year = cut(year, 
                         breaks = seq(1969, 2014, 5), 
                         labels = year_bins)) %&gt;% 
  mutate(clean_test = factor(clean_test, 
                             levels = c("nowomen", "notalk", "men",
                                        "dubious", "ok")))
```

---

## How about over time? (Stacked)


```r
library(fivethirtyeight)
library(ggplot2)
ggplot(data = bechdel,
       mapping = aes(x = five_year, fill = clean_test)) +
  geom_bar()
```

![](slide_deck_files/figure-html/unnamed-chunk-23-1.png)&lt;!-- --&gt;

---

## How about over time? (Side-by-side)


```r
library(fivethirtyeight)
library(ggplot2)
ggplot(data = bechdel,
       mapping = aes(x = five_year, fill = clean_test)) +
  geom_bar(position = "dodge")
```

![](slide_deck_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

---

## How about over time? (Stacked proportional)


```r
library(fivethirtyeight)
library(ggplot2)
ggplot(data = bechdel,
       mapping = aes(x = five_year, fill = clean_test)) +
  geom_bar(position = "fill", color = "black")
```

![](slide_deck_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;

---

class: center, middle

## `ggplot2` is for beginners and for data science professionals!

&lt;a href="https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/"&gt;&lt;img src="figure/bechdel.png" width=500&gt;&lt;/a&gt;

---

## Practice

Produce appropriate 5NG with R package &amp; data set in [ ], e.g., [`nycflights13` `\(\rightarrow\)` `weather`] 

&lt;!--
Try to look through the help documentation/Google to improve your plots
--&gt;

1. Does `age` predict `recline_rude`? &lt;br&gt; [`fivethirtyeight` `\(\rightarrow\)` `na.omit(flying)`]

2. Distribution of `age` by `sex` &lt;br&gt; [`okcupiddata` `\(\rightarrow\)` `profiles`]

3. Does `budget` predict `rating`? &lt;br&gt; [`ggplot2movies` `\(\rightarrow\)` `movies`]

4. Distribution of log base 10 scale of `budget_2013` &lt;br&gt; [`fivethirtyeight` `\(\rightarrow\)` `bechdel`]

---

### HINTS

![](slide_deck_files/figure-html/unnamed-chunk-26-1.png)&lt;!-- --&gt;



---

class: inverse, center, middle

# DEMO in RStudio

---

class: center, middle

### Determining the appropriate plot

&lt;a href="https://coggle.it/diagram/V_G2gzukTDoQ-aZt"&gt;&lt;img src="figure/viz_mindmap.png" style="width: 400px;"/&gt;&lt;/a&gt;

---

class: center, middle

# Chapter 5: Data Wrangling

---

### `gapminder` data frame in the `gapminder` package


```r
library(gapminder)
gapminder
```

```
# A tibble: 1,704 × 6
       country continent  year lifeExp      pop gdpPercap
        &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
1  Afghanistan      Asia  1952  28.801  8425333  779.4453
2  Afghanistan      Asia  1957  30.332  9240934  820.8530
3  Afghanistan      Asia  1962  31.997 10267083  853.1007
4  Afghanistan      Asia  1967  34.020 11537966  836.1971
5  Afghanistan      Asia  1972  36.088 13079460  739.9811
6  Afghanistan      Asia  1977  38.438 14880372  786.1134
7  Afghanistan      Asia  1982  39.854 12881816  978.0114
8  Afghanistan      Asia  1987  40.822 13867957  852.3959
9  Afghanistan      Asia  1992  41.674 16317921  649.3414
10 Afghanistan      Asia  1997  41.763 22227415  635.3414
# ... with 1,694 more rows
```

---

## Base R versus the `tidyverse`

Say we wanted mean life expectancy across all years for Asia
--


```r
# Base R
asia &lt;- gapminder[gapminder$continent == "Asia", ]
mean(asia$lifeExp)
```

```
[1] 60.0649
```
--
 

```r
library(dplyr)
gapminder %&gt;% filter(continent == "Asia") %&gt;%
  summarize(mean_exp = mean(lifeExp))
```

```
# A tibble: 1 × 1
  mean_exp
     &lt;dbl&gt;
1  60.0649
```

---

## The pipe `%&gt;%`

&lt;img src="figure/pipe.png" width="245" /&gt; &amp;emsp; &amp;emsp;&lt;img src="figure/MagrittePipe.jpg" width="504" /&gt;
--

- A way to chain together commands
--

- It is *essentially* the `dplyr` equivalent to the &lt;br&gt; `+` in `ggplot2`

---

## The 5NG of data viz
--

### `geom_point()`&lt;br&gt; `geom_line()` &lt;br&gt; `geom_histogram()`&lt;br&gt;  `geom_boxplot()`&lt;br&gt; `geom_bar()`

---

# The Five Main Verbs (5MV) of data wrangling

### `filter()` &lt;br&gt; `summarize()` &lt;br&gt; `group_by()` &lt;br&gt; `mutate()` &lt;br&gt; `arrange()`

---

## `filter()`

- Select a subset of the rows of a data frame. 

- The arguments are the "filters" that you'd like to apply.
--


```r
library(gapminder); library(dplyr)
gap_2007 &lt;- gapminder %&gt;% filter(year == 2007)
head(gap_2007)
```

```
# A tibble: 6 × 6
      country continent  year lifeExp      pop  gdpPercap
       &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;
1 Afghanistan      Asia  2007  43.828 31889923   974.5803
2     Albania    Europe  2007  76.423  3600523  5937.0295
3     Algeria    Africa  2007  72.301 33333216  6223.3675
4      Angola    Africa  2007  42.731 12420476  4797.2313
5   Argentina  Americas  2007  75.320 40301927 12779.3796
6   Australia   Oceania  2007  81.235 20434176 34435.3674
```

- Use `==` to compare a variable to a value

---

## Logical operators

- Use `|` to check for any in multiple filters being true:
--


```r
gapminder %&gt;% 
  filter(year == 2002 | continent == "Europe")
```
--


```
# A tibble: 472 × 6
       country continent  year lifeExp      pop gdpPercap
        &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
1  Afghanistan      Asia  2002  42.129 25268405  726.7341
2      Albania    Europe  1952  55.230  1282697 1601.0561
3      Albania    Europe  1957  59.280  1476505 1942.2842
4      Albania    Europe  1962  64.820  1728137 2312.8890
5      Albania    Europe  1967  66.220  1984060 2760.1969
6      Albania    Europe  1972  67.690  2263554 3313.4222
7      Albania    Europe  1977  68.930  2509048 3533.0039
8      Albania    Europe  1982  70.420  2780097 3630.8807
9      Albania    Europe  1987  72.000  3075321 3738.9327
10     Albania    Europe  1992  71.581  3326498 2497.4379
# ... with 462 more rows
```

---

## Logical operators

- Use `&amp;` or `,` to check for all of multiple filters being true:
--


```r
gapminder %&gt;% 
  filter(year == 2002, continent == "Europe")
```


```
# A tibble: 30 × 6
                  country continent  year lifeExp      pop gdpPercap
                   &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
1                 Albania    Europe  2002  75.651  3508512  4604.212
2                 Austria    Europe  2002  78.980  8148312 32417.608
3                 Belgium    Europe  2002  78.320 10311970 30485.884
4  Bosnia and Herzegovina    Europe  2002  74.090  4165416  6018.975
5                Bulgaria    Europe  2002  72.140  7661799  7696.778
6                 Croatia    Europe  2002  74.876  4481020 11628.389
7          Czech Republic    Europe  2002  75.510 10256295 17596.210
8                 Denmark    Europe  2002  77.180  5374693 32166.500
9                 Finland    Europe  2002  78.370  5193039 28204.591
10                 France    Europe  2002  79.590 59925035 28926.032
# ... with 20 more rows
```

---

## Logical operators

- Use `%in%` to check for any being true &lt;br&gt; (shortcut to using `|` repeatedly with `==`)
--


```r
gapminder %&gt;% 
  filter(country %in% c("Argentina", "Belgium", "Mexico"),
         year %in% c(1987, 1992))
```
--


```
# A tibble: 6 × 6
    country continent  year lifeExp      pop gdpPercap
     &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
1 Argentina  Americas  1987  70.774 31620918  9139.671
2 Argentina  Americas  1992  71.868 33958947  9308.419
3   Belgium    Europe  1987  75.350  9870200 22525.563
4   Belgium    Europe  1992  76.460 10045622 25575.571
5    Mexico  Americas  1987  69.498 80122492  8688.156
6    Mexico  Americas  1992  71.455 88111030  9472.384
```


---

## `summarize()`

- Any numerical summary that you want to apply to a column of a data frame is specified within `summarize()`.


```r
max_exp_1997 &lt;- gapminder %&gt;% 
  filter(year == 1997) %&gt;% 
  summarize(max_exp = max(lifeExp))
max_exp_1997
```
--


```
# A tibble: 1 × 1
  max_exp
    &lt;dbl&gt;
1   80.69
```



---

### Combining `summarize()` with `group_by()`

When you'd like to determine a numerical summary for all
levels of a different categorical variable


```r
max_exp_1997_by_cont &lt;- gapminder %&gt;% 
  filter(year == 1997) %&gt;% 
  group_by(continent) %&gt;%
  summarize(max_exp = max(lifeExp))
max_exp_1997_by_cont
```

--

```
# A tibble: 5 × 2
  continent max_exp
     &lt;fctr&gt;   &lt;dbl&gt;
1    Africa  74.772
2  Americas  78.610
3      Asia  80.690
4    Europe  79.390
5   Oceania  78.830
```

---

## `ggplot2` revisited

For aggregated data, use `geom_col`


```r
ggplot(data = max_exp_1997_by_cont, 
       mapping = aes(x = continent, y = max_exp)) +
  geom_col()
```

![](slide_deck_files/figure-html/unnamed-chunk-41-1.png)&lt;!-- --&gt;

---


## The 5MV

- `filter()`
- `summarize()`
- `group_by()`

--

- `mutate()`

--

- `arrange()`

---

## `mutate()`

- Allows you to 
    1. &lt;font color="blue"&gt;create a new variable with a specific value&lt;/font&gt; OR
    2. create a new variable based on other variables OR
    3. change the contents of an existing variable

--


```r
gap_plus &lt;- gapminder %&gt;% mutate(just_one = 1)
head(gap_plus)
```

```
# A tibble: 6 × 7
      country continent  year lifeExp      pop gdpPercap just_one
       &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 Afghanistan      Asia  1952  28.801  8425333  779.4453        1
2 Afghanistan      Asia  1957  30.332  9240934  820.8530        1
3 Afghanistan      Asia  1962  31.997 10267083  853.1007        1
4 Afghanistan      Asia  1967  34.020 11537966  836.1971        1
5 Afghanistan      Asia  1972  36.088 13079460  739.9811        1
6 Afghanistan      Asia  1977  38.438 14880372  786.1134        1
```

---

## `mutate()`

- Allows you to 
    1. create a new variable with a specific value OR
    2. &lt;font color="blue"&gt;create a new variable based on other variables&lt;/font&gt; OR
    3. change the contents of an existing variable

--


```r
gap_w_gdp &lt;- gapminder %&gt;% mutate(gdp = pop * gdpPercap)
head(gap_w_gdp)
```

```
# A tibble: 6 × 7
      country continent  year lifeExp      pop gdpPercap         gdp
       &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;       &lt;dbl&gt;
1 Afghanistan      Asia  1952  28.801  8425333  779.4453  6567086330
2 Afghanistan      Asia  1957  30.332  9240934  820.8530  7585448670
3 Afghanistan      Asia  1962  31.997 10267083  853.1007  8758855797
4 Afghanistan      Asia  1967  34.020 11537966  836.1971  9648014150
5 Afghanistan      Asia  1972  36.088 13079460  739.9811  9678553274
6 Afghanistan      Asia  1977  38.438 14880372  786.1134 11697659231
```

---

## `mutate()`

- Allows you to 
    1. create a new variable with a specific value OR
    2. create a new variable based on other variables OR
    3. &lt;font color="blue"&gt;change the contents of an existing variable&lt;/font&gt;

--


```r
gap_weird &lt;- gapminder %&gt;% mutate(pop = pop + 1000)
head(gap_weird)
```

```
# A tibble: 6 × 6
      country continent  year lifeExp      pop gdpPercap
       &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 Afghanistan      Asia  1952  28.801  8426333  779.4453
2 Afghanistan      Asia  1957  30.332  9241934  820.8530
3 Afghanistan      Asia  1962  31.997 10268083  853.1007
4 Afghanistan      Asia  1967  34.020 11538966  836.1971
5 Afghanistan      Asia  1972  36.088 13080460  739.9811
6 Afghanistan      Asia  1977  38.438 14881372  786.1134
```

---

## `arrange()`

- Reorders the rows in a data frame based on the values of one or more variables
--


```r
gapminder %&gt;%
  arrange(year, country)
```

```
# A tibble: 1,704 × 6
       country continent  year lifeExp      pop  gdpPercap
        &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;
1  Afghanistan      Asia  1952  28.801  8425333   779.4453
2      Albania    Europe  1952  55.230  1282697  1601.0561
3      Algeria    Africa  1952  43.077  9279525  2449.0082
4       Angola    Africa  1952  30.015  4232095  3520.6103
5    Argentina  Americas  1952  62.485 17876956  5911.3151
6    Australia   Oceania  1952  69.120  8691212 10039.5956
7      Austria    Europe  1952  66.800  6927772  6137.0765
8      Bahrain      Asia  1952  50.939   120447  9867.0848
9   Bangladesh      Asia  1952  37.484 46886859   684.2442
10     Belgium    Europe  1952  68.000  8730405  8343.1051
# ... with 1,694 more rows
```

---

## `arrange()`

- Can also put into descending order
--


```r
gapminder %&gt;%
  filter(year &gt; 2000) %&gt;%
  arrange(desc(lifeExp))
```

---

## Don't mix up `arrange` and `group_by`

- `group_by` is used (mostly) with `summarize` to calculate summaries over groups

- `arrange` is used for sorting

---

## Don't mix up `arrange` and `group_by`

This doesn't really do anything useful


```r
gapminder %&gt;% group_by(year)
```

```
Source: local data frame [1,704 x 6]
Groups: year [12]

       country continent  year lifeExp      pop gdpPercap
        &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
1  Afghanistan      Asia  1952  28.801  8425333  779.4453
2  Afghanistan      Asia  1957  30.332  9240934  820.8530
3  Afghanistan      Asia  1962  31.997 10267083  853.1007
4  Afghanistan      Asia  1967  34.020 11537966  836.1971
5  Afghanistan      Asia  1972  36.088 13079460  739.9811
6  Afghanistan      Asia  1977  38.438 14880372  786.1134
7  Afghanistan      Asia  1982  39.854 12881816  978.0114
8  Afghanistan      Asia  1987  40.822 13867957  852.3959
9  Afghanistan      Asia  1992  41.674 16317921  649.3414
10 Afghanistan      Asia  1997  41.763 22227415  635.3414
# ... with 1,694 more rows
```

---

## Don't mix up `arrange` and `group_by`

But this does


```r
gapminder %&gt;% arrange(year)
```

```
# A tibble: 1,704 × 6
       country continent  year lifeExp      pop  gdpPercap
        &lt;fctr&gt;    &lt;fctr&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;      &lt;dbl&gt;
1  Afghanistan      Asia  1952  28.801  8425333   779.4453
2      Albania    Europe  1952  55.230  1282697  1601.0561
3      Algeria    Africa  1952  43.077  9279525  2449.0082
4       Angola    Africa  1952  30.015  4232095  3520.6103
5    Argentina  Americas  1952  62.485 17876956  5911.3151
6    Australia   Oceania  1952  69.120  8691212 10039.5956
7      Austria    Europe  1952  66.800  6927772  6137.0765
8      Bahrain      Asia  1952  50.939   120447  9867.0848
9   Bangladesh      Asia  1952  37.484 46886859   684.2442
10     Belgium    Europe  1952  68.000  8730405  8343.1051
# ... with 1,694 more rows
```

---

## Changing of observation unit

True or False

&gt; Each of `filter`, `mutate`, and `arrange` change the observational unit.

--

True or False

&gt; `group_by() %&gt;% summarize()` changes the observational unit.

&lt;!-- 
Draw diagram for average monthly temp aggregated like on rstudio::conf slides
--&gt;

---

## What is meant by "joining data frames" and why is it useful?

--

&lt;img src="https://ismayc.github.io/moderndiver-book/images/join-inner.png" style="display: block; margin: auto;" /&gt;

---

### Does cost of living in a state relate to whether police officers live in the cities they patrol?  What about state political ideology?


```r
library(fivethirtyeight)
library(readr)
ideology &lt;- read_csv("https://ismayc.github.io/Effective-Data-Storytelling-using-the-tidyverse/datasets/ideology.csv")
police_join &lt;- inner_join(x = police_locals, y = ideology, by = "city")
police_join
```

```
# A tibble: 75 × 10
           city force_size       all      white non_white     black
          &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1      New York      32300 0.6179567 0.44638656 0.7644189 0.7708914
2       Chicago      12120 0.8750000 0.87196262 0.8774003 0.8974057
3   Los Angeles      10100 0.2282178 0.15277778 0.2638484 0.3873874
4    Washington       9340 0.1156317 0.05677419 0.1573651 0.1701891
5       Houston       7700 0.2922078 0.17373461 0.3992583 0.3663793
6  Philadelphia       6045 0.8354012 0.77689873 0.8994801 0.9246575
7       Phoenix       4475 0.3117318 0.27080182 0.4273504 0.5217391
8     San Diego       4460 0.3621076 0.37298387 0.3484848 0.5384615
9        Dallas       3605 0.1914008 0.17150396 0.2134503 0.2146341
10      Detroit       3265 0.3705972 0.08196721 0.5427873 0.5680000
# ... with 65 more rows, and 4 more variables: hispanic &lt;dbl&gt;,
#   asian &lt;dbl&gt;, state &lt;chr&gt;, state_ideology &lt;chr&gt;
```

---


```r
cost_of_living &lt;- read_csv("https://ismayc.github.io/Effective-Data-Storytelling-using-the-tidyverse/datasets/cost_of_living.csv")
police_join_cost &lt;- inner_join(x = police_join, y = cost_of_living, by = "state")
police_join_cost
```

```
# A tibble: 75 × 12
           city force_size       all      white non_white     black
          &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1      New York      32300 0.6179567 0.44638656 0.7644189 0.7708914
2       Chicago      12120 0.8750000 0.87196262 0.8774003 0.8974057
3   Los Angeles      10100 0.2282178 0.15277778 0.2638484 0.3873874
4    Washington       9340 0.1156317 0.05677419 0.1573651 0.1701891
5       Houston       7700 0.2922078 0.17373461 0.3992583 0.3663793
6  Philadelphia       6045 0.8354012 0.77689873 0.8994801 0.9246575
7       Phoenix       4475 0.3117318 0.27080182 0.4273504 0.5217391
8     San Diego       4460 0.3621076 0.37298387 0.3484848 0.5384615
9        Dallas       3605 0.1914008 0.17150396 0.2134503 0.2146341
10      Detroit       3265 0.3705972 0.08196721 0.5427873 0.5680000
# ... with 65 more rows, and 6 more variables: hispanic &lt;dbl&gt;,
#   asian &lt;dbl&gt;, state &lt;chr&gt;, state_ideology &lt;chr&gt;, index &lt;dbl&gt;,
#   col_group &lt;chr&gt;
```

---

### Does cost of living in a state relate to whether police officers live in the cities they patrol?  What about state political ideology?


```r
ggplot(data = police_join_cost,
       mapping = aes(x = index, y = all)) +
  geom_point(aes(color = state_ideology)) +
  labs(x = "Cost of Living Index", y = "% Officers Living in City")
```

![](slide_deck_files/figure-html/unnamed-chunk-51-1.png)&lt;!-- --&gt;

---


## Practice

Use the 5MV to answer problems from R data packages, e.g., [`nycflights13` `\(\rightarrow\)` `weather`] 

&lt;!--
Try to look through the help documentation/Google to improve your plots
--&gt;

1. What is the maximum arrival delay for each carrier departing JFK? &lt;br&gt; [`nycflights13` `\(\rightarrow\)` `flights`]

2. Calculate the domestic return on investment for 2013 scaled data and sort from highest at the top to lowest at the bottom &lt;br&gt; [`fivethirtyeight` `\(\rightarrow\)` `bechdel`]

3. Include the name of the `carrier` as a column in the `flights` data frame [`nycflights13` `\(\rightarrow\)` `flights`, `airlines`]

---


class: inverse, center, middle

# DEMO in RStudio

---

class: inverse, center, middle

# Statistical Inference

---

## Statistical Inference

We now enter the "traditional" topics of intro stats...

1. Sampling theory
1. Hypothesis testing
1. Confidence intervals
1. Regression

---

## Statistical Inference

... but now students are armed with

1. Data visualization
1. Data wrangling skills
1. **Most important**: comfort with coding!

---

# Chapter 6: Sampling Highlights

Sampling is at the root of statistics. Two approaches:

&lt;br&gt;

Either we use this...            |  Or we use this...
:-------------------------:|:-------------------------:
&lt;img src="figure/formulas.png" alt="Drawing" style="width: 300px;"/&gt;   |  &lt;img src="figure/coding.jpg" alt="Drawing" style="width: 300px;"/&gt; 

&lt;br&gt;

---

## `mosaic` Package

It has functions for random simulations:

&lt;br&gt;

1. `rflip()`: Flip a coin
1. `shuffle()`: Shuffle a set of values
1. `do()`: Do the same thing many, many, many times
1. `resample()`: the **swiss army knife** for sampling

---

## Lady Tasting Tea

&lt;center&gt;&lt;img src="figure/lady_tasting_tea.jpg" alt="Drawing" style="height: 450px;"/&gt;&lt;/center&gt;


---

## Presented to Students As:

* Say you are a statistician and you meet someone called the "Lady Tasting Tea."
* She claims she can tell by tasting whether the tea or the milk was added first to a cup.
* You want to test whether
    + She can actually tell which came first
    + She's lying and is really guessing at random
* Say you have just enough tea/milk to pour into 8 cups.

---

## Lady Tasting Tea

The example will be built around this code:  (Available in the supplementary HTML document [here].)


```r
library(ggplot2)
library(dplyr)
library(mosaic)

single_cup_guess &lt;- c(1, 0)
simulation &lt;- do(10000) * resample(single_cup_guess, size=8, replace=TRUE)
View(simulation)

simulation &lt;- simulation %&gt;% 
  mutate(n_correct = V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8) 
View(simulation)

ggplot(simulation, aes(x=n_correct)) + 
  geom_bar() +
  labs(x="Number of Guesses Correct", title="Number Correct Assuming She Is Guessing at Random") +
  geom_vline(xintercept=8, col="red")
```

---

# Chapter 7: Hypothesis Testing Highlights

**There is only one test; it has 5 components**:

1. Define `\(H_0\)` and `\(H_A\)`
1. Define the test statistic `\(\delta\)`
1. Compute the observed test statistic `\(\delta^*\)`
1. Construct the null distribution either
    * Mathematically
    * **Via Simulation**
1. Compare `\(\delta^*\)` to null distribution to compute p-value

---

## There is Only One Test: Lady Tasting Tea

1. She is guessing at random vs she can tell which came first
1. Test statistic: Number out of 8 shes guesses right
1. Observed test statistic: 8 of 8. The red line!
1. Null distribution: (simulated) bar graph!
1. p-value: Very small! Above 0.36%

---

## There is Only One Test: Goodness-of-Fit

1. Observations fit expected distibution vs not
1. Test statistic: `\(\sum_{i=1}^{k}\frac{\left(\mbox{Obs}_i-\mbox{Exp}_i\right)^2}{\mbox{Exp}_i}\)`
1. Observed test statistic: Compute using data!
1. Null Distribution: (mathematically derived) [Chi-Squared Dist'n](https://beta.rstudioconnect.com/connect/#/apps/2719/access).
1. Area to the right!

---

## There is Only One Test

&lt;center&gt;&lt;img src="figure/ht.png" alt="Drawing" style="width: 700px;"/&gt;&lt;/center&gt;

---


# Chapter 8: Confidence Intervals Highlights

* Not only show students repeated sampling (with a Shiny app for example), let them repeatedly sample!
* In other words, let them construct sampling distributions.

---
  
## Sampling Distribution, SE, &amp; C.I. Example
  
The example will be built around this code:  (Available in the supplementary HTML document [here].)

1. Discuss with your seatmates what all 5 code parts below are doing.
1. Try increasing `n` and repeating. What does this correspond to doing in real life?
1. How does the histogram change?
1. Describe using statistical language the role `n` plays when it comes to estimating `\(\mu\)`.


```r
library(ggplot2)
library(dplyr)
library(mosaic)
library(okcupiddata)
data(profiles)

# For simplicity, remove 3 individuals who did not list their height
profiles &lt;- profiles %&gt;% 
  filter(!is.na(height))

# Population mean
mu &lt;- mean(profiles$height)

# Sample size:
n &lt;- 5

# Parts 1 &amp; 2:
resample(profiles$height, size=n, replace=TRUE)
mean(resample(profiles$height, size=n, replace=TRUE))

# Part 3:
samples &lt;- do(10000) * mean(resample(profiles$height, size=n, replace=TRUE))
View(samples)

# Part 4:
ggplot(samples, aes(x=mean)) +
  geom_histogram(binwidth = 1) +
  labs(x="sample mean") + 
  xlim(c(50,80)) +
  geom_vline(xintercept=mu, col="red")

# Part 5:
sd(samples$mean)
```


---
  
## The Hard Part

Convincing students:

* We only do the blue via simulation *as a theoretical exercise*
* We do the purple in *real life*

&lt;br&gt;

&lt;center&gt;&lt;img src="figure/SE.png" alt="Drawing" style="width: 800px;"/&gt;&lt;/center&gt;

---

# Chapter 9: Regression Highlights

1. Experience with `ggplot2` package and knowledge of the Grammar of Graphics primes students for regression
1. Use of the `broom` package to unpack regression

---

## 1. `ggplot2` Primes Regression

* Mapping aesthetics to variables provides a natural framework for all of data visualization.  Understanding the relationships between variables is clear and transparent from the `ggplot2` code.
* This ultimately what regression is about!

---

## 1. `ggplot2` Primes Regression

Example:

* All Alaskan Airlines and Frontier flights leaving NYC in 2013
* We want to study the relationship between temperature and departure delay
* For summer (June, July, August) and non-summer months separately

Involves four variables: 

- `carrier`, `temp`, `dep_delay`, `summer`

---

## 1. `ggplot2` Primes Regression

![](slide_deck_files/figure-html/unnamed-chunk-54-1.png)&lt;!-- --&gt;

---

## 1. `ggplot2` Primes Regression

Why? Dig deeper into data. Look at `origin` and `dest` variables as well:

&lt;br&gt; 


```
Source: local data frame [2 x 4]
Groups: carrier, origin [?]

  carrier origin  dest `Number of Flights`
    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;               &lt;int&gt;
1      AS    EWR   SEA                 712
2      F9    LGA   DEN                 675
```

---


## 2. `broom` Package

* The `broom` package takes the messy output of built-in modeling functions in R, such as
`lm`, `nls`, or `t.test`, and turns them into tidy data frames.
* Fits in with `tidyverse` ecosystem
* This works for [many R data types](https://github.com/tidyverse/broom#available-tidiers)!

---

## 2. `broom` Package

In our case, `broom` functions take `lm` objects as inputs and return the following in tidy format!

* `tidy()`: regression output table
* `augment()`: point-by-point values (fitted values, residuals, predicted values)
* `glance()`: scalar summaries like `\(R^2\)`, 

---

## 2. `broom` Package

The chapter will be built around this code:  (Available in the supplementary HTML document [here].)


```r
library(ggplot2)
library(dplyr)
library(nycflights13)
library(knitr)
library(broom)
set.seed(2017)

# Load Alaska data, deleting rows that have missing departure delay
# or arrival delay data
alaska_flights &lt;- flights %&gt;% 
  filter(carrier == "AS") %&gt;% 
  filter(!is.na(dep_delay) &amp; !is.na(arr_delay)) %&gt;% 
  sample_n(50)
View(alaska_flights)


# Exploratory Data Analysis----------------------------------------------------
# Plot of sample of points:
ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + 
   geom_point()

# Correlation coefficient:
alaska_flights %&gt;% 
  summarize(correl = cor(dep_delay, arr_delay))

# Add regression line
ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red")


# Fit Regression and Study Output with broom Package---------------------------
# Fit regression
delay_fit &lt;- lm(formula = arr_delay ~ dep_delay, data = alaska_flights)

# 1. broom::tidy() regression table with confidence intervals and no p-value stars
regression_table &lt;- delay_fit %&gt;% 
  tidy(conf.int=TRUE)
regression_table %&gt;% 
  kable(digits=3)

# 2. broom::augment() for point-by-point values
regression_points &lt;- delay_fit %&gt;% 
  augment() %&gt;% 
  select(arr_delay, dep_delay, .fitted, .resid) 
regression_points %&gt;% 
  head() %&gt;% 
  kable(digits=3)

# and for prediction
new_flights &lt;- data_frame(dep_delay = c(25, 30, 15))
delay_fit %&gt;% 
  augment(newdata = new_flights) %&gt;% 
  kable()

# 3. broom::glance() scalar summaries of regression
regression_summaries &lt;- delay_fit %&gt;% 
  glance() 
regression_summaries %&gt;% 
  kable(digits=3)


# Residual Analysis------------------------------------------------------------
ggplot(data = regression_points, mapping = aes(x = .resid)) +
  geom_histogram(binwidth=10) +
  geom_vline(xintercept = 0, color = "blue")
ggplot(data = regression_points, mapping = aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 0, color = "blue")
ggplot(data = regression_points, mapping = aes(sample = .resid)) +
  stat_qq()


# Preview of Multiple Regression-----------------------------------------------
flights_subset &lt;- flights %&gt;% 
  filter(carrier == "AS" | carrier == "F9") %&gt;% 
  left_join(weather, by=c("year", "month", "day", "hour", "origin")) %&gt;% 
  filter(dep_delay &lt; 250) %&gt;% 
  mutate(summer = ifelse(month == 6 | month == 7 | month == 8, "Summer Flights", "Non-Summer Flights"))

ggplot(data = flights_subset, mapping = aes(x = temp, y=dep_delay, col=carrier)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~summer)
```

---

---

class: inverse, center, middle

# The Future of ModernDive

---

## The Immediate Future

By July 1st, 2017

* Complete Development of Chapters 6-9 on Simulations, Hypothesis Testing, Confidence Intervals, and Regression
* Learning Checks: Discussion/solutions embedded directly in the textbook, that you can reveal progressively.
* Have better [data frame printing](http://rmarkdown.rstudio.com/html_document_format.html#data_frame_printing). Instead of raw R code use
    + Less jarring `knitr::kable()` output or
    + Interactive table outputs, to partically replicate RStudio's `View()` function.

---

## The Longer Term

* In Chapter 9: Regression
    + Add more on categorical predictors
    + Multiple regression

---

## The Longer Term

### DataCamp

- Continue to build supplementary materials for other disciplines
  - [Effective Data Storytelling using the tidyverse](https://www.datacamp.com/courses/effective-data-storytelling-using-the-tidyverse) designed for Social Scientists/Data Journalists
  - Add [DataCamp Light](https://github.com/datacamp/datacamp-light) chunks into the book to enable student practice right there inside the textbook via the `tutorial` [package](https://github.com/datacamp/tutorial)

---

## The Longer Term 

### Implement Cognitive Science Research

- Work on interleaving and spaced practice inside the textbook to improve student learning and retention
- Follow the [principles and research](http://www.learningscientists.org/posters) laid out by the [Learning Scientists](http://www.learningscientists.org/)

---

## The Longer Term 

## Further Develop Interactive Applets

- To help students visualize and understand inferential processes
  - [Sampling app](https://ismay.shinyapps.io/okcupidheights/)
  - [Probability Distribution Viewer and Calculator](http://ismay.shinyapps.io/ProbApp)
- (MAYBE) Learn D3.js and create applets like those at [Seeing Theory](http://students.brown.edu/seeing-theory/)

---


class: inverse, center, middle

## Introduction to `bookdown`

---


## What is Markdown?

 - A "plaintext formatting syntax"
 - Type in plain text, render to more complex formats
 - One step beyond writing a `txt` file
 - Render to HTML, PDF, DOCX, etc. using Pandoc

---

## What does it look like?

.left-column[
```
  # Header 1
  
  ## Header 2
  
  Normal paragraphs of text go here.
  
  **I'm bold**
  
  [links!](http://rstudio.com)
  
   * Unordered
   * Lists   
   
  And  Tables
  ---- -------
  Like This
  
```
]

.right-column[
&lt;img src="figure/markdown.png" alt="markdown" style="width: 270px;"/&gt;
]

---

## What is R Markdown?
  
- "Literate programming"
- Embed R code in a Markdown document
- Renders textual output along with graphics

***

.left-column[
```

```{r chunk1}
library(ggplot2)
library(nycflights13)
pdx_flights &lt;- flights %&gt;% 
  filter(dest == "PDX", month == 5)
nrow(pdx_flights)
```

```{r chunk2}
ggplot(data = pdx_flights,
  mapping = aes(x = arr_delay, 
                y = dep_delay)) +
  geom_point()
```

```
]

.right-column[

```
[1] 88
```

![](slide_deck_files/figure-html/unnamed-chunk-57-1.png)&lt;!-- --&gt;
]

---

## What is `bookdown`?

From [bookdown book about `bookdown`](https://bookdown.org/yihui/bookdown/):

&gt; Author books with R Markdown, including generating figures and tables, and inserting cross-references, citations, HTML widgets, and Shiny apps in R Markdown. The book can be exported to HTML, PDF, and e-books (e.g. EPUB). The book style is customizable. You can easily write and preview the book in RStudio IDE or other editors, and host the book wherever you want (e.g. bookdown.org).

---

class: inverse, center, middle

# DEMO of `bookdown` &lt;br&gt; with ModernDive Light
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
